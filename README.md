# ğŸ“ *Image Enhancement using Knowledge Distillation*

This project aims to **compress a powerful image enhancement model** (MSAFN) into a **lightweight student model** (LightMSAFN) using **knowledge distillation**. The goal is to retain most of the image quality (PSNR, SSIM) while reducing model size and computation time, making it ideal for **real-time enhancement** on resource-constrained devices.

- ğŸ“Œ **Task**: Super-resolution / Image Enhancement  
- ğŸ§  **Teacher Model**: Multi-Scale Attention Fusion Network (MSAFN)  
- ğŸ“ **Student Model**: LightMSAFN (lightweight, fast, mobile-friendly)  
- ğŸ”„ **Technique**: Knowledge distillation via combined pixel + soft loss  
- ğŸ“Š **Training Dataset**: Vimeo-90K (15 sequences subset with augmentation)  
- âœ… **Goal**: Achieve high SSIM (>0.94) and PSNR (~29 dB) in a compressed model

---

## ğŸ§  *Teacher Model (MSAFN)*
The **Multi-Scale Attention Fusion Network (MSAFN)** is an advanced teacher model designed for high-fidelity image sharpening and restoration. Built for knowledge distillation, it processes images through parallel **multi-scale pathways (48Ã—48, 24Ã—24, 12Ã—12 resolutions)** with integrated channel attention gates that dynamically recalibrate feature importance. The architecture features stochastic depth residual blocks for robust feature extraction and a GRU-based recurrent refinement module that progressively enhances details through 3 iterative steps.

Engineered for stability during training, MSAFN includes **NaN-protected operations with automatic batch skipping**, dynamic augmentation scaling to combat performance plateaus, and gradient centralization for accelerated convergence. It employs a hybrid L1 + stabilized SSIM loss function and OneCycle LR scheduling (up to 3e-4) for optimal performance. The model processes Vimeo90K datasets efficiently in multi-GPU environments while maintaining VRAM usage under 12GB at 64 batch sizes, delivering state-of-the-art sharpening results ideal for distilling knowledge into lightweight student networks.

---

## ğŸ§  *Student Training with Knowledge Distillation (MSAFN â†’ LightMSAFN)*

This PyTorch implementation presents a **lightweight Multi-Scale Attention Fusion Network (LightMSAFN)** trained via **knowledge distillation** from a powerful **MSAFN teacher model**, achieving efficient image enhancement/super-resolution on the **Vimeo-90K dataset**. The student model leverages logit distillation (KL divergence) and intermediate feature mimicking (MSE loss) to transfer knowledge while maintaining only 30% of the teacher's parameters through strategic architectural optimizations - **including channel reduction (64â†’32), shallower residual blocks (8â†’3), and elimination of recurrent components. The training protocol employs adaptive loss weighting (Î±=0.7 distillation + Î²=0.3 ground truth), OneCycle LR scheduling (2e-4 max), and mixed-precision acceleration, enabling the compact student to deliver comparable visual quality to the teacher at 2.8Ã— faster inference speeds, making it ideal for edge deployment**. Critical enhancements like gradient centralization and progressive teacher guidance decay ensure stable convergence while preserving the teacher's restoration capabilities in a dramatically more efficient architecture.

---

## âœ¨ Highlights

- ğŸ”¥ **Teacher**: MSAFN â€” deep, multi-scale residual transformer-like model  
- âš¡ **Student**: LightMSAFN â€” compressed and fast model with comparable performance  
- ğŸ“ **Knowledge Distillation**: Balanced L1 + Soft Loss from teacher predictions  
- ğŸ§ª **Mixed Precision Training**: Faster training with AMP (`autocast`)  
- ğŸ“Š **Evaluation**: SSIM + PSNR tracking with best model checkpointing  
- ğŸ§¼ **NaN-safe Augmentations**: Resilient training with strong image augmentations  
- ğŸ—ï¸ **Modular Design**: Easily extensible and clean training pipeline

---

## ğŸ—ï¸ Architecture Overview

### ğŸ‘¨â€ğŸ« MSAFN (Teacher Model)
- Multi-scale processing (1Ã—, 2Ã—, 4Ã— downsampling)
- Residual Dense Blocks with attention gates
- Recurrent refinement via GRU-like module
- ~8.1M parameters

### ğŸ‘¨â€ğŸ“ LightMSAFN (Student Model)
- Lightweight channel attention & residual blocks
- Efficient fusion and reduced-depth refinement
- Distilled from teacher using pixel + soft loss
- ~0.8M parameters

---

## ğŸ—‚ï¸ Dataset

- ğŸ“ **Vimeo-90K** (custom subset)
- Resolution: 256Ã—256 crops
- Format: Raw `.png` sequences
- Data Augmentations:
  - Random flips & rotations
  - Brightness jitter
  - Gaussian noise
  - Bicubic downsample + upscale for LR generation

## ğŸ“¦ Vimeo-90K Dataset
- The Vimeo-90K dataset is a large-scale, high-quality video dataset commonly used for video enhancement tasks such as video super-resolution, frame interpolation, and video denoising. It was introduced in the paper:

- TOFlow: Video Enhancement with Task-Oriented Flow
Tianfan Xue, Baian Chen, Jiajun Wu, Donglai Wei, William T. Freeman

## ğŸ“ Structure
- The dataset contains 91,701 video clips, each consisting of 7 consecutive frames (448Ã—256 resolution). It includes two main subsets:

- Vimeo-90K Septuplet â€“ used for tasks like super-resolution, denoising, and deblurring

- Vimeo-90K Triplet â€“ often used for video frame interpolation

- Each clip is organized in a folder containing PNG images named im1.png through im7.png.


## ğŸ” Applications
- Video Super-Resolution

- Frame Interpolation

- Motion Compensation

- Video Denoising

- Optical Flow Estimation



---

## ğŸ§ª Loss Functions

| Loss Type         | Description                                     |
|-------------------|-------------------------------------------------|
| `L1`              | Student vs Ground Truth (pixel reconstruction)  |
| `MSE`             | Student vs Teacher Output (soft guidance)       |
| `DistillationLoss`| Combined: `alpha * L1 + (1-alpha) * MSE`        |

`alpha = 0.5` (can be tuned)

---

## ğŸ“ˆ Metrics

- âœ… **PSNR** (Peak Signal-to-Noise Ratio)
- âœ… **SSIM** (Structural Similarity Index)
- âœ… Logged per epoch + visualized via tqdm bar

---

## ğŸš€ Training Pipeline

### ğŸ“¦ Requirements
```bash
pip install streamlit==1.28.0
torch==2.0.1
torchvision==0.15.2
numpy==1.24.3
Pillow==10.0.0
opencv-python-headless==4.7.0.72
tqdm==4.65.0 

````

### ğŸ§ª Run Training
```bash
!python3 teacher_training.py
``` 
---
```bash
!python3 student_training.py
```

### ğŸ› ï¸ Configuration

| Parameter       | Value                    |
| --------------- | ------------------------ |
| Epochs          | 40                       |
| Batch Size      | 64                       |
| Patch Size      | 64X64                    |
| Optimizer       | AdamW                    |
| Scheduler       | ReduceLROnPlateau        |
| Mixed Precision | âœ… Yes (`torch.cuda.amp`) |
| LR              | 1e-3 (with decay)        |
| Gradient Clip   | 0.5                      |
| GPUs Used       | Auto (`nn.DataParallel`) |

---

## ğŸ§  File Structure

```
student_training.py
â”œâ”€â”€ MSAFN           # Teacher model
â”œâ”€â”€ LightMSAFN      # Student model
â”œâ”€â”€ Vimeo90KDataset # Dataset with strong augmentation
â”œâ”€â”€ DistillationLoss# Custom loss combining L1 & MSE
â”œâ”€â”€ Training Loop   # AMP, distillation, metric tracking
â””â”€â”€ Model Saving    # Best & final model checkpoints
```

---

## ğŸ Sample Results

| Metric    | Teacher (MSAFN) | Student (LightMSAFN) | Upon Validation |
| --------- | --------------- | -------------------- |-----------------|
| PSNR (dB) | \~29.6          | \~28.9               | \~51              |
| SSIM      | \~0.9423        | \~0.9416             | \~0.98           |
| Speed     | 1Ã— (slow)       | âš¡ 3â€“4Ã— faster        | âš¡4Ã— faster    |
| Params    | \~8.1M          | \~0.8M               | \~0.03M         |

---

## ğŸ“¦ Model Checkpoints

| Path                                      | Description        |
| ----------------------------------------- | ------------------ |
| `/kaggle/input/msafncustom/*.pth`         | Pretrained teacher |
| `/kaggle/working/best_student_*.pth`      | Best student model |
| `/kaggle/working/final_student_model.pth` | Final checkpoint   |

---

## âœï¸ Authors

| Name            | Role                                | GitHub                                                | LinkedIn                                                |
|-----------------|-------------------------------------|--------------------------------------------------------|----------------------------------------------------------|
| **Ayush Sharma** |  Deep Learning Researcher(Teacher Model)              | [@AyushS1304](https://github.com/AyushS1304)           | [Ayush Sharma](https://linkedin.com/in/Ayush)            |
| **Dhruv Agarwal** |  Deep Learning Researcher(Student Model)             | [@Dhruv610ag](https://github.com/yourgithub)           | [Dhruv Agarwal](https://linkedin.com/in/dhruv)           |
| **Aniket Shah**  | Frontend Developer(StreamLit)                       | [@Aniket200424](https://github.com/Aniket200424)           | [Aniket Shah](https://linkedin.com/in/AniketShah)        |

---

## ğŸ’¬ Acknowledgements

* [Vimeo-90K Dataset](http://toflow.csail.mit.edu/)
* Inspired by works on lightweight SR and knowledge distillation in vision

---


"A great teacher empowers beyond their own architecture." â€“ *MSAFN Mentor Model*


"Knowledge distilled is power amplified." â€“ *LightMSAFN Student Model ğŸ˜„*


ğŸ§ ğŸ« Teacher: "My layers may be deep, but my wisdom runs deeper."
âš¡ğŸ“ Student: "Learning fast by standing on stacked convolutions!"

---

You can now run this in a Kaggle or Colab notebook cell, and it will create a `README.md` file in your working directory. Let me know if you want to include diagrams, inference scripts, or visual results too.



```bash
git clone https://github.com/AyushS1304/RefiNet.git
```
---
